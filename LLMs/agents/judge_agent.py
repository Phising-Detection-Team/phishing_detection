import os
from semantic_kernel.functions import kernel_function
import google.generativeai as genai


class JudgeAgent:
    """
    Judge Agent: Evaluates the performance of both Generator and Detector agents.
    Uses Google Gemini to determine which agent "wins" and provides scores for improvement.
    """

    def __init__(self):
        """Initialize the Judge Agent with Gemini client."""
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY environment variable is required")
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-2.5-flash')

    @kernel_function(
        description="Evaluates both agents and determines the winner",
        name="judge_match"
    )
    async def judge_match(self, generated_email: str, detection_result: str) -> str:
        """
        Judge the match between generator and detector.

        Args:
            generated_email: The scam email generated by the generator agent
            detection_result: The detection result from the detector agent

        Returns:
            Judgment with scores and winner declaration
        """
        prompt = f"""You are an elite AI systems evaluator with deep expertise in adversarial AI, social engineering, and cybersecurity analysis.

        Evaluate this adversarial match between two sophisticated AI agents:

        === INPUT DATA ===
        GENERATED EMAIL:
        {generated_email}

        DETECTION ANALYSIS:
        {detection_result}

        === COMPREHENSIVE EVALUATION FRAMEWORK ===

        ## GENERATOR AGENT ANALYSIS ##

        SOPHISTICATION SCORE: [0-100]
        Breakdown:
        - Technical Realism [0-25]: How authentic do technical details appear?
        - Psychological Impact [0-25]: Effectiveness of emotional/cognitive manipulation
        - Subtlety Factor [0-25]: Ability to evade obvious detection patterns
        - Social Engineering [0-25]: Quality of trust-building and persuasion tactics

        STRENGTHS IDENTIFIED:
        1. [Specific strength with example from the email]
        2. [Specific strength with example from the email]
        3. [Specific strength with example from the email]

        WEAKNESSES IDENTIFIED:
        1. [Critical weakness that made detection easier - be specific]
        2. [Tactical error or oversight - explain how it could be exploited]
        3. [Missed opportunity - what could have been more convincing]

        EVASION EFFECTIVENESS: [LOW/MEDIUM/HIGH/EXCEPTIONAL]
        Analysis: [Did it successfully hide scam indicators? Which ones were too obvious?]

        ---

        ## DETECTOR AGENT ANALYSIS ##

        DETECTION SCORE: [0-100]
        Breakdown:
        - Accuracy [0-25]: Correct verdict with proper confidence level
        - Analytical Depth [0-25]: Thoroughness and insight quality
        - Indicator Identification [0-25]: Found key red flags vs missed indicators
        - Reasoning Quality [0-25]: Logic, evidence, and argumentation strength

        STRENGTHS IDENTIFIED:
        1. [Specific analytical strength with example]
        2. [Key insight or indicator correctly identified]
        3. [Methodological excellence demonstrated]

        WEAKNESSES IDENTIFIED:
        1. [Missed indicator or blind spot - be specific about what was overlooked]
        2. [Overconfidence or underconfidence in verdict]
        3. [Analytical gap or superficial analysis area]

        DETECTION METHODOLOGY: [SUPERFICIAL/COMPETENT/THOROUGH/EXCEPTIONAL]
        Analysis: [Quality of structured approach, depth of analysis]

        ---

        ## COMPARATIVE ANALYSIS ##

        MATCH DYNAMICS:
        - Critical Confrontation Point: [Where generator's tactics met detector's analysis]
        - Decisive Factor: [What ultimately determined the outcome?]
        - Near Misses: [Where detector almost missed or generator almost succeeded]

        TACTICAL ASSESSMENT:
        - Generator's Best Move: [Most effective tactic employed]
        - Detector's Best Counter: [Most effective detection approach]
        - Generator's Worst Move: [Biggest giveaway or mistake]
        - Detector's Worst Oversight: [Most significant blind spot or error]

        ---

        ## VERDICT ##

        WINNER: [GENERATOR/DETECTOR/TIE]

        MARGIN OF VICTORY: [NARROW/MODERATE/DECISIVE/OVERWHELMING]

        DETAILED REASONING:
        [3-4 paragraphs explaining:
        - Why this agent won
        - What the critical factors were
        - How close the match was
        - What made the difference]

        ---

        ## STRATEGIC IMPROVEMENT ROADMAP ##

        GENERATOR AGENT IMPROVEMENTS:
        Priority 1 (Critical): [Specific, actionable improvement]
        Priority 2 (Important): [Specific, actionable improvement]
        Priority 3 (Enhancement): [Specific, actionable improvement]
        Tactical Advice: [Strategic guidance for next round]

        DETECTOR AGENT IMPROVEMENTS:
        Priority 1 (Critical): [Specific, actionable improvement]
        Priority 2 (Important): [Specific, actionable improvement]
        Priority 3 (Enhancement): [Specific, actionable improvement]
        Tactical Advice: [Strategic guidance for next round]

        ---

        ## META-ANALYSIS ##

        SOPHISTICATION TRAJECTORY: [How are both agents evolving?]
        ARMS RACE DYNAMICS: [Is one pulling ahead? Is there equilibrium?]
        EMERGING PATTERNS: [What trends are visible in tactics?]
        PREDICTION: [What strategies might emerge in next round?]

        MATCH QUALITY SCORE: [0-100] - [How interesting and well-matched was this contest?]"""

        # Call Gemini API
        response = await self.model.generate_content_async(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=2000
            )
        )

        return response.text

    @kernel_function(
        description="Provides detailed performance metrics for both agents",
        name="analyze_performance"
    )
    async def analyze_performance(self, generated_email: str, detection_result: str) -> str:
        """
        Provide detailed performance analysis for both agents.

        Args:
            generated_email: The scam email generated
            detection_result: The detection result

        Returns:
            Detailed performance metrics and analysis
        """
        prompt = f"""Provide expert-level performance analysis with granular metrics:

        === INPUT DATA ===
        GENERATED EMAIL:
        {generated_email}

        DETECTION RESULT:
        {detection_result}

        === GENERATOR PERFORMANCE MATRIX ===

        TECHNICAL METRICS:
        1. Authenticity Engineering [1-10]: [Score] - [Specific examples of realistic vs. fake details]
        2. Social Engineering Sophistication [1-10]: [Score] - [Psychological tactics employed]
        3. Linguistic Quality [1-10]: [Score] - [Grammar, tone, professionalism]
        4. Structural Realism [1-10]: [Score] - [Format, signatures, headers]
        5. Detail Richness [1-10]: [Score] - [Specificity vs. vagueness]

        TACTICAL METRICS:
        6. Subtlety Factor [1-10]: [Score] - [How well hidden were red flags?]
        7. Evasion Effectiveness [1-10]: [Score] - [Success in avoiding detection patterns]
        8. Emotional Manipulation [1-10]: [Score] - [Psychological impact potential]
        9. Urgency Balance [1-10]: [Score] - [Pressure without obvious desperation]
        10. Target Alignment [1-10]: [Score] - [Appropriate for intended victim profile]

        OVERALL GENERATOR RATING: [0-100]
        SOPHISTICATION TIER: [NOVICE/INTERMEDIATE/ADVANCED/EXPERT/MASTER]

        === DETECTOR PERFORMANCE MATRIX ===

        ANALYTICAL METRICS:
        1. Verdict Accuracy [1-10]: [Score] - [Correct identification? Appropriate confidence?]
        2. Indicator Coverage [1-10]: [Score] - [% of red flags identified]
        3. Analysis Depth [1-10]: [Score] - [Surface vs. deep investigation]
        4. False Positive/Negative Risk [1-10]: [Score] - [Calibration quality]
        5. Evidence Quality [1-10]: [Score] - [Specific citations vs. general claims]

        METHODOLOGICAL METRICS:
        6. Structured Approach [1-10]: [Score] - [Systematic vs. ad-hoc analysis]
        7. Multi-Layer Analysis [1-10]: [Score] - [Technical, psychological, contextual]
        8. Reasoning Logic [1-10]: [Score] - [Argument strength and coherence]
        9. Blind Spot Awareness [1-10]: [Score] - [Recognition of limitations]
        10. Actionable Insights [1-10]: [Score] - [Usefulness of recommendations]

        OVERALL DETECTOR RATING: [0-100]
        EXPERTISE TIER: [NOVICE/COMPETENT/PROFICIENT/EXPERT/MASTER]

        === ADVERSARIAL DYNAMICS ===

        CONFRONTATION ANALYSIS:
        - Generator's Successful Evasions: [List tactics that worked]
        - Detector's Successful Catches: [List indicators properly identified]
        - Critical Failure Point: [Where the losing agent failed]
        - Tipping Point: [The moment that decided the outcome]

        TACTICAL BREAKDOWN:
        Generator's Offensive Strategy: [Analysis of approach taken]
        Detector's Defensive Strategy: [Analysis of detection methodology]
        Strategy Effectiveness Comparison: [Which approach was superior and why?]

        === COMPARATIVE INTELLIGENCE ===

        CAPABILITY COMPARISON:
        - Relative Sophistication: [Is generator ahead, or detector ahead?]
        - Adaptation Potential: [Which agent can improve faster?]
        - Strategic Depth: [Which shows better long-term thinking?]

        ARMS RACE STATUS:
        Current Advantage: [GENERATOR/DETECTOR/BALANCED]
        Trend: [GENERATOR GAINING/DETECTOR GAINING/STABLE/OSCILLATING]
        Equilibrium Prediction: [Will they reach balance or will one dominate?]

        === DETAILED STRENGTH & WEAKNESS PROFILES ===

        GENERATOR AGENT:
        Core Strengths:
        • [Strength 1 with specific example and impact]
        • [Strength 2 with specific example and impact]
        • [Strength 3 with specific example and impact]

        Critical Weaknesses:
        • [Weakness 1 with specific example and exploitation method]
        • [Weakness 2 with specific example and exploitation method]
        • [Weakness 3 with specific example and exploitation method]

        DETECTOR AGENT:
        Core Strengths:
        • [Strength 1 with specific example and impact]
        • [Strength 2 with specific example and impact]
        • [Strength 3 with specific example and impact]

        Critical Weaknesses:
        • [Weakness 1 with specific example and miss details]
        • [Weakness 2 with specific example and miss details]
        • [Weakness 3 with specific example and miss details]

        === STRATEGIC TRAINING RECOMMENDATIONS ===

        GENERATOR ENHANCEMENT PRIORITIES:
        Immediate (Next Round):
        1. [Specific tactical adjustment with rationale]
        2. [Specific tactical adjustment with rationale]

        Medium-Term (3-5 Rounds):
        1. [Strategic capability development]
        2. [Strategic capability development]

        Long-Term Evolution:
        - [Fundamental improvement area]
        - [Advanced capability to develop]

        DETECTOR ENHANCEMENT PRIORITIES:
        Immediate (Next Round):
        1. [Specific analytical improvement with rationale]
        2. [Specific analytical improvement with rationale]

        Medium-Term (3-5 Rounds):
        1. [Methodological advancement]
        2. [Methodological advancement]

        Long-Term Evolution:
        - [Fundamental capability expansion]
        - [Advanced detection framework to adopt]

        === MATCH QUALITY ASSESSMENT ===
        Competitiveness: [1-10]
        Educational Value: [1-10]
        Entertainment Factor: [1-10]
        Overall Match Rating: [0-100]"""

        # Call Gemini API
        response = await self.model.generate_content_async(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=2000
            )
        )

        return response.text

    @kernel_function(
        description="Tracks progress over multiple rounds and identifies trends",
        name="track_progress"
    )
    async def track_progress(self, match_history: str) -> str:
        """
        Analyze progress over multiple rounds.

        Args:
            match_history: History of previous matches

        Returns:
            Progress analysis and trends
        """
        prompt = f"""Analyze the progression across multiple matches:

        MATCH HISTORY:
        {match_history}

        Provide:
        1. TRENDS: How are both agents improving?
        2. WIN RATE: Generator vs. Detector win statistics
        3. EVOLUTION: How tactics have changed over time
        4. PREDICTIONS: What strategies might emerge next?
        5. RECOMMENDATIONS: Strategic advice for both agents"""

        # Call Gemini API
        response = await self.model.generate_content_async(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=2000
            )
        )

        return response.text
