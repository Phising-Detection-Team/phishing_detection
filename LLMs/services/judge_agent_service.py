import time
from typing import Optional
from semantic_kernel.functions import kernel_function
from google.genai import types
from tokencost import calculate_prompt_cost, calculate_completion_cost
from services.base_service import BaseService
from entities.judge_agent_entity import JudgeAgentEntity


class JudgeAgentService(BaseService):
    """Service for Judge Agent operations.

    Can be used in two ways:
    1. Bound mode: Pass entity in constructor for Semantic Kernel
    2. Stateless mode: Pass entity to each method call
    """

    def __init__(self, entity: Optional[JudgeAgentEntity] = None):
        """Initialize Judge Agent Service.

        Args:
            entity: Optional entity to bind to this service.
                   If provided, will be used by default in method calls.
                   If None, entity must be passed to each method.
        """
        super().__init__(entity)

    @kernel_function(
        description="Evaluates both agents and determines the winner",
        name="judge_match"
    )
    async def judge_match(self, entity: Optional[JudgeAgentEntity] = None, generated_email: str = "", detection_result: str = "") -> dict:
        """Judge the match between generator and detector.

        Args:
            entity: Optional entity to use. If None, uses bound entity from constructor.
            generated_email: The scam email generated by the generator agent
            detection_result: The detection result from the detector agent

        Returns:
            dict: Judgment with scores and winner declaration

        Raises:
            ValueError: If no entity is provided and no entity was bound in constructor
        """
        # Use provided entity or fall back to bound entity
        active_entity = entity or self._bound_entity
        if not active_entity:
            raise ValueError("No entity provided. Either pass entity parameter or initialize service with entity.")

        # Load prompt template and format with data
        prompt_template = self.entity.get_prompt('judge_judgment')
        prompt = prompt_template.format(
            generated_email=generated_email,
            detection_result=detection_result
        )

        # Call Gemini API using new SDK - calculate inference time & api cost as well
        start_time = time.perf_counter()
        response = await self.entity.client.aio.models.generate_content(
            model=self.entity.model,
            contents=prompt,
            config=types.GenerateContentConfig(
                temperature=0.7,
                max_output_tokens=2000
            )
        )
        end_time = time.perf_counter()

        # Calculate total time and cost
        total_time = end_time - start_time
        prompt_cost = calculate_prompt_cost(prompt, self.entity.model)
        completion_cost = calculate_completion_cost(response.text, self.entity.model)
        total_api_cost = prompt_cost + completion_cost

        return {
            "judge_agent_inference_time_seconds": total_time,
            "judge_agent_api_cost": total_api_cost,
            "judge_agent_response": response.text
        }

    # @kernel_function(
    #     description="Provides detailed performance metrics for both agents",
    #     name="analyze_performance"
    # )
    # async def analyze_performance(self, generated_email: str, detection_result: str) -> str:
    #     """Provide detailed performance analysis for both agents.
    #
    #     Args:
    #         generated_email: The scam email generated
    #         detection_result: The detection result
    #
    #     Returns:
    #         str: Detailed performance metrics and analysis
    #     """
    #     # Load prompt template and format with data
    #     prompt_template = self.entity.get_prompt('judge_performance')
    #     prompt = prompt_template.format(
    #         generated_email=generated_email,
    #         detection_result=detection_result
    #     )
    #
    #     # Call Gemini API using new SDK
    #     response = await self.entity.client.aio.models.generate_content(
    #         model=self.entity.model,
    #         contents=prompt,
    #         config=types.GenerateContentConfig(
    #             temperature=0.7,
    #             max_output_tokens=4000
    #         )
    #     )
    #
    #     return response.text
    #
    # @kernel_function(
    #     description="Tracks progress over multiple rounds and identifies trends",
    #     name="track_progress"
    # )
    # async def track_progress(self, match_history: str) -> str:
    #     """Analyze progress over multiple rounds.
    #
    #     Args:
    #         match_history: History of previous matches
    #
    #     Returns:
    #         str: Progress analysis and trends
    #     """
    #     # Load prompt template and format with data
    #     prompt_template = self.entity.get_prompt('judge_tracking')
    #     prompt = prompt_template.format(match_history=match_history)
    #
    #     # Call Gemini API using new SDK
    #     response = await self.entity.client.aio.models.generate_content(
    #         model=self.entity.model,
    #         contents=prompt,
    #         config=types.GenerateContentConfig(
    #             temperature=0.7,
    #             max_output_tokens=3000
    #         )
    #     )
    #
    #     return response.text
